{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOY7T5-V81Yo"
      },
      "source": [
        "# Training and inference on an example dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlV70jDuWzea"
      },
      "source": [
        "In this notebook we'll install SLEAP, download a sample dataset, run training and inference on that dataset using the SLEAP command-line interface, and then download the predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX9noEb8m8re"
      },
      "source": [
        "## Install SLEAP\n",
        "Note: Before installing SLEAP check [SLEAP releases](https://github.com/talmolab/sleap/releases) page for the latest version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUfnkxMtLcK3",
        "outputId": "9f7e98ee-4442-4f8c-aa55-61304e4b3413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.1/904.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.3/90.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.3/336.3 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.9/832.9 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.5.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "fastai 2.7.15 requires pillow>=9.0.0, but you have pillow 8.4.0 which is incompatible.\n",
            "flax 0.8.3 requires rich>=11.1, but you have rich 10.16.1 which is incompatible.\n",
            "ibis-framework 8.0.0 requires rich<14,>=12.4.4, but you have rich 10.16.1 which is incompatible.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "referencing 0.35.1 requires attrs>=22.2.0, but you have attrs 21.4.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.8.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -qqq -y opencv-python opencv-contrib-python\n",
        "!pip install -qqq \"sleap[pypi]>=1.3.3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq7jrgUksLtR"
      },
      "source": [
        "## Download sample training data into Colab\n",
        "Let's download a sample dataset from the SLEAP [sample datasets repository](https://github.com/talmolab/sleap-datasets) into Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm3cU1Bc0tWc",
        "outputId": "e97f56fc-439b-4586-bebf-a2e4905bbd57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 1s (84.2 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "--2024-05-14 11:56:02--  https://github.com/talmolab/sleap-datasets/releases/download/dm-courtship-v1/drosophila-melanogaster-courtship.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/263375180/16df8d00-94f1-11ea-98d1-6c03a2f89e1c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240514%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240514T115603Z&X-Amz-Expires=300&X-Amz-Signature=d3991445cf04ed5489e728b66d241c959956ce573f2c5b2231cca411e164e5ac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=263375180&response-content-disposition=attachment%3B%20filename%3Ddrosophila-melanogaster-courtship.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-14 11:56:03--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/263375180/16df8d00-94f1-11ea-98d1-6c03a2f89e1c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240514%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240514T115603Z&X-Amz-Expires=300&X-Amz-Signature=d3991445cf04ed5489e728b66d241c959956ce573f2c5b2231cca411e164e5ac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=263375180&response-content-disposition=attachment%3B%20filename%3Ddrosophila-melanogaster-courtship.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 111973079 (107M) [application/octet-stream]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 106.79M  67.8MB/s    in 1.6s    \n",
            "\n",
            "2024-05-14 11:56:04 (67.8 MB/s) - ‘dataset.zip’ saved [111973079/111973079]\n",
            "\n",
            "Archive:  dataset.zip\n",
            "   creating: dataset/drosophila-melanogaster-courtship/\n",
            "  inflating: dataset/drosophila-melanogaster-courtship/.DS_Store  \n",
            "   creating: dataset/__MACOSX/\n",
            "   creating: dataset/__MACOSX/drosophila-melanogaster-courtship/\n",
            "  inflating: dataset/__MACOSX/drosophila-melanogaster-courtship/._.DS_Store  \n",
            "  inflating: dataset/drosophila-melanogaster-courtship/20190128_113421.mp4  \n",
            "  inflating: dataset/__MACOSX/drosophila-melanogaster-courtship/._20190128_113421.mp4  \n",
            "  inflating: dataset/drosophila-melanogaster-courtship/courtship_labels.slp  \n",
            "  inflating: dataset/__MACOSX/drosophila-melanogaster-courtship/._courtship_labels.slp  \n",
            "  inflating: dataset/drosophila-melanogaster-courtship/example.jpg  \n",
            "  inflating: dataset/__MACOSX/drosophila-melanogaster-courtship/._example.jpg  \n",
            "\u001b[01;34mdataset\u001b[0m\n",
            "├── \u001b[01;34mdrosophila-melanogaster-courtship\u001b[0m\n",
            "│   ├── \u001b[01;32m20190128_113421.mp4\u001b[0m\n",
            "│   ├── \u001b[01;32mcourtship_labels.slp\u001b[0m\n",
            "│   └── \u001b[01;35mexample.jpg\u001b[0m\n",
            "└── \u001b[01;34m__MACOSX\u001b[0m\n",
            "    └── \u001b[01;34mdrosophila-melanogaster-courtship\u001b[0m\n",
            "\n",
            "3 directories, 3 files\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tree\n",
        "!wget -O dataset.zip https://github.com/talmolab/sleap-datasets/releases/download/dm-courtship-v1/drosophila-melanogaster-courtship.zip\n",
        "!mkdir dataset\n",
        "!unzip dataset.zip -d dataset\n",
        "!rm dataset.zip\n",
        "!tree dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-sr67av5uu"
      },
      "source": [
        "## Train models\n",
        "For the top-down pipeline, we'll need train two models: a centroid model and a centered-instance model.\n",
        "\n",
        "Using the command-line interface, we'll first train a model for centroids using the default **training profile**. The training profile determines the model architecture, the learning rate, and other parameters.\n",
        "\n",
        "When you start training, you'll first see the training parameters and then the training and validation loss for each training epoch.\n",
        "\n",
        "As soon as you're satisfied with the validation loss you see for an epoch during training, you're welcome to stop training by clicking the stop button. The version of the model with the lowest validation loss is saved during training, and that's what will be used for inference.\n",
        "\n",
        "If you don't stop training, it will run for 200 epochs or until validation loss fails to improve for some number of epochs (controlled by the `early_stopping` fields in the training profile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKf6qzMqNBUi",
        "outputId": "1968f9f5-0fec-47c2-ee06-f2aac7920a29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "2024-05-14 11:56:10.045743: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-05-14 11:56:10.045778: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "INFO:sleap.nn.training:Versions:\n",
            "SLEAP: 1.4.0\n",
            "TensorFlow: 2.8.4\n",
            "Numpy: 1.22.4\n",
            "Python: 3.10.12\n",
            "OS: Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "INFO:sleap.nn.training:Training labels file: dataset/drosophila-melanogaster-courtship/courtship_labels.slp\n",
            "INFO:sleap.nn.training:Training profile: /usr/local/lib/python3.10/dist-packages/sleap/training_profiles/baseline.centroid.json\n",
            "INFO:sleap.nn.training:\n",
            "INFO:sleap.nn.training:Arguments:\n",
            "INFO:sleap.nn.training:{\n",
            "    \"training_job_path\": \"baseline.centroid.json\",\n",
            "    \"labels_path\": \"dataset/drosophila-melanogaster-courtship/courtship_labels.slp\",\n",
            "    \"video_paths\": [\n",
            "        \"dataset/drosophila-melanogaster-courtship/20190128_113421.mp4\"\n",
            "    ],\n",
            "    \"val_labels\": null,\n",
            "    \"test_labels\": null,\n",
            "    \"base_checkpoint\": null,\n",
            "    \"tensorboard\": false,\n",
            "    \"save_viz\": false,\n",
            "    \"zmq\": false,\n",
            "    \"run_name\": \"courtship.centroid\",\n",
            "    \"prefix\": \"\",\n",
            "    \"suffix\": \"\",\n",
            "    \"cpu\": false,\n",
            "    \"first_gpu\": false,\n",
            "    \"last_gpu\": false,\n",
            "    \"gpu\": \"auto\"\n",
            "}\n",
            "INFO:sleap.nn.training:\n",
            "INFO:sleap.nn.training:Training job:\n",
            "INFO:sleap.nn.training:{\n",
            "    \"data\": {\n",
            "        \"labels\": {\n",
            "            \"training_labels\": null,\n",
            "            \"validation_labels\": null,\n",
            "            \"validation_fraction\": 0.1,\n",
            "            \"test_labels\": null,\n",
            "            \"split_by_inds\": false,\n",
            "            \"training_inds\": null,\n",
            "            \"validation_inds\": null,\n",
            "            \"test_inds\": null,\n",
            "            \"search_path_hints\": [],\n",
            "            \"skeletons\": []\n",
            "        },\n",
            "        \"preprocessing\": {\n",
            "            \"ensure_rgb\": false,\n",
            "            \"ensure_grayscale\": false,\n",
            "            \"imagenet_mode\": null,\n",
            "            \"input_scaling\": 0.5,\n",
            "            \"pad_to_stride\": null,\n",
            "            \"resize_and_pad_to_target\": true,\n",
            "            \"target_height\": null,\n",
            "            \"target_width\": null\n",
            "        },\n",
            "        \"instance_cropping\": {\n",
            "            \"center_on_part\": null,\n",
            "            \"crop_size\": null,\n",
            "            \"crop_size_detection_padding\": 16\n",
            "        }\n",
            "    },\n",
            "    \"model\": {\n",
            "        \"backbone\": {\n",
            "            \"leap\": null,\n",
            "            \"unet\": {\n",
            "                \"stem_stride\": null,\n",
            "                \"max_stride\": 16,\n",
            "                \"output_stride\": 2,\n",
            "                \"filters\": 16,\n",
            "                \"filters_rate\": 2.0,\n",
            "                \"middle_block\": true,\n",
            "                \"up_interpolate\": true,\n",
            "                \"stacks\": 1\n",
            "            },\n",
            "            \"hourglass\": null,\n",
            "            \"resnet\": null,\n",
            "            \"pretrained_encoder\": null\n",
            "        },\n",
            "        \"heads\": {\n",
            "            \"single_instance\": null,\n",
            "            \"centroid\": {\n",
            "                \"anchor_part\": null,\n",
            "                \"sigma\": 2.5,\n",
            "                \"output_stride\": 2,\n",
            "                \"loss_weight\": 1.0,\n",
            "                \"offset_refinement\": false\n",
            "            },\n",
            "            \"centered_instance\": null,\n",
            "            \"multi_instance\": null,\n",
            "            \"multi_class_bottomup\": null,\n",
            "            \"multi_class_topdown\": null\n",
            "        },\n",
            "        \"base_checkpoint\": null\n",
            "    },\n",
            "    \"optimization\": {\n",
            "        \"preload_data\": true,\n",
            "        \"augmentation_config\": {\n",
            "            \"rotate\": true,\n",
            "            \"rotation_min_angle\": -15.0,\n",
            "            \"rotation_max_angle\": 15.0,\n",
            "            \"translate\": false,\n",
            "            \"translate_min\": -5,\n",
            "            \"translate_max\": 5,\n",
            "            \"scale\": false,\n",
            "            \"scale_min\": 0.9,\n",
            "            \"scale_max\": 1.1,\n",
            "            \"uniform_noise\": false,\n",
            "            \"uniform_noise_min_val\": 0.0,\n",
            "            \"uniform_noise_max_val\": 10.0,\n",
            "            \"gaussian_noise\": false,\n",
            "            \"gaussian_noise_mean\": 5.0,\n",
            "            \"gaussian_noise_stddev\": 1.0,\n",
            "            \"contrast\": false,\n",
            "            \"contrast_min_gamma\": 0.5,\n",
            "            \"contrast_max_gamma\": 2.0,\n",
            "            \"brightness\": false,\n",
            "            \"brightness_min_val\": 0.0,\n",
            "            \"brightness_max_val\": 10.0,\n",
            "            \"random_crop\": false,\n",
            "            \"random_crop_height\": 256,\n",
            "            \"random_crop_width\": 256,\n",
            "            \"random_flip\": false,\n",
            "            \"flip_horizontal\": true\n",
            "        },\n",
            "        \"online_shuffling\": true,\n",
            "        \"shuffle_buffer_size\": 128,\n",
            "        \"prefetch\": true,\n",
            "        \"batch_size\": 4,\n",
            "        \"batches_per_epoch\": null,\n",
            "        \"min_batches_per_epoch\": 200,\n",
            "        \"val_batches_per_epoch\": null,\n",
            "        \"min_val_batches_per_epoch\": 10,\n",
            "        \"epochs\": 200,\n",
            "        \"optimizer\": \"adam\",\n",
            "        \"initial_learning_rate\": 0.0001,\n",
            "        \"learning_rate_schedule\": {\n",
            "            \"reduce_on_plateau\": true,\n",
            "            \"reduction_factor\": 0.5,\n",
            "            \"plateau_min_delta\": 1e-08,\n",
            "            \"plateau_patience\": 5,\n",
            "            \"plateau_cooldown\": 3,\n",
            "            \"min_learning_rate\": 1e-08\n",
            "        },\n",
            "        \"hard_keypoint_mining\": {\n",
            "            \"online_mining\": false,\n",
            "            \"hard_to_easy_ratio\": 2.0,\n",
            "            \"min_hard_keypoints\": 2,\n",
            "            \"max_hard_keypoints\": null,\n",
            "            \"loss_scale\": 5.0\n",
            "        },\n",
            "        \"early_stopping\": {\n",
            "            \"stop_training_on_plateau\": true,\n",
            "            \"plateau_min_delta\": 1e-08,\n",
            "            \"plateau_patience\": 20\n",
            "        }\n",
            "    },\n",
            "    \"outputs\": {\n",
            "        \"save_outputs\": true,\n",
            "        \"run_name\": \"courtship.centroid\",\n",
            "        \"run_name_prefix\": \"\",\n",
            "        \"run_name_suffix\": null,\n",
            "        \"runs_folder\": \"models\",\n",
            "        \"tags\": [],\n",
            "        \"save_visualizations\": true,\n",
            "        \"delete_viz_images\": true,\n",
            "        \"zip_outputs\": false,\n",
            "        \"log_to_csv\": true,\n",
            "        \"checkpointing\": {\n",
            "            \"initial_model\": false,\n",
            "            \"best_model\": true,\n",
            "            \"every_epoch\": false,\n",
            "            \"latest_model\": false,\n",
            "            \"final_model\": false\n",
            "        },\n",
            "        \"tensorboard\": {\n",
            "            \"write_logs\": false,\n",
            "            \"loss_frequency\": \"epoch\",\n",
            "            \"architecture_graph\": false,\n",
            "            \"profile_graph\": false,\n",
            "            \"visualizations\": true\n",
            "        },\n",
            "        \"zmq\": {\n",
            "            \"subscribe_to_controller\": false,\n",
            "            \"controller_address\": \"tcp://127.0.0.1:9000\",\n",
            "            \"controller_polling_timeout\": 10,\n",
            "            \"publish_updates\": false,\n",
            "            \"publish_address\": \"tcp://127.0.0.1:9001\"\n",
            "        }\n",
            "    },\n",
            "    \"name\": \"\",\n",
            "    \"description\": \"\",\n",
            "    \"sleap_version\": \"1.4.0\",\n",
            "    \"filename\": \"/usr/local/lib/python3.10/dist-packages/sleap/training_profiles/baseline.centroid.json\"\n",
            "}\n",
            "INFO:sleap.nn.training:\n",
            "2024-05-14 11:56:15.702120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-14 11:56:15.702668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-05-14 11:56:15.702976: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-05-14 11:56:15.703212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-05-14 11:56:15.703439: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-05-14 11:56:16.232311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-05-14 11:56:16.236733: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "INFO:sleap.nn.training:Running in CPU-only mode.\n",
            "INFO:sleap.nn.training:System:\n",
            "GPUs: None detected.\n",
            "INFO:sleap.nn.training:\n",
            "INFO:sleap.nn.training:Initializing trainer...\n",
            "INFO:sleap.nn.training:Loading training labels from: dataset/drosophila-melanogaster-courtship/courtship_labels.slp\n",
            "INFO:sleap.nn.training:Creating training and validation splits from validation fraction: 0.1\n",
            "INFO:sleap.nn.training:  Splits: Training = 134 / Validation = 15.\n",
            "INFO:sleap.nn.training:Setting up for training...\n",
            "INFO:sleap.nn.training:Setting up pipeline builders...\n",
            "INFO:sleap.nn.training:Setting up model...\n",
            "INFO:sleap.nn.training:Building test pipeline...\n",
            "2024-05-14 11:56:18.228481: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO:sleap.nn.training:Loaded test example. [2.298s]\n",
            "INFO:sleap.nn.training:  Input shape: (512, 512, 3)\n",
            "INFO:sleap.nn.training:Created Keras model.\n",
            "INFO:sleap.nn.training:  Backbone: UNet(stacks=1, filters=16, filters_rate=2.0, kernel_size=3, stem_kernel_size=7, convs_per_block=2, stem_blocks=0, down_blocks=4, middle_block=True, up_blocks=3, up_interpolate=True, block_contraction=False)\n",
            "INFO:sleap.nn.training:  Max stride: 16\n",
            "INFO:sleap.nn.training:  Parameters: 1,953,393\n",
            "INFO:sleap.nn.training:  Heads: \n",
            "INFO:sleap.nn.training:    [0] = CentroidConfmapsHead(anchor_part=None, sigma=2.5, output_stride=2, loss_weight=1.0)\n",
            "INFO:sleap.nn.training:  Outputs: \n",
            "INFO:sleap.nn.training:    [0] = KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=None), name='CentroidConfmapsHead/BiasAdd:0', description=\"created by layer 'CentroidConfmapsHead'\")\n",
            "INFO:sleap.nn.training:Training from scratch\n",
            "INFO:sleap.nn.training:Setting up data pipelines...\n",
            "INFO:sleap.nn.training:Training set: n = 134\n",
            "INFO:sleap.nn.training:Validation set: n = 15\n",
            "INFO:sleap.nn.training:Setting up optimization...\n",
            "INFO:sleap.nn.training:  Learning rate schedule: LearningRateScheduleConfig(reduce_on_plateau=True, reduction_factor=0.5, plateau_min_delta=1e-08, plateau_patience=5, plateau_cooldown=3, min_learning_rate=1e-08)\n",
            "INFO:sleap.nn.training:  Early stopping: EarlyStoppingConfig(stop_training_on_plateau=True, plateau_min_delta=1e-08, plateau_patience=20)\n",
            "INFO:sleap.nn.training:Setting up outputs...\n",
            "INFO:sleap.nn.training:Created run path: models/courtship.centroid\n",
            "INFO:sleap.nn.training:Setting up visualization...\n",
            "2024-05-14 11:56:23.551432: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -34 } dim { size: -35 } dim { size: -36 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"101\" frequency: 2000 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 40370176 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -37 } dim { size: -38 } dim { size: 1 } } }\n",
            "2024-05-14 11:56:25.385680: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -34 } dim { size: -35 } dim { size: -36 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"101\" frequency: 2000 num_cores: 2 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 1048576 l3_cache_size: 40370176 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -37 } dim { size: -38 } dim { size: 1 } } }\n",
            "Unable to use Qt backend for matplotlib. This probably means Qt is running headless.\n",
            "Unable to use Qt backend for matplotlib. This probably means Qt is running headless.\n",
            "INFO:sleap.nn.training:Finished trainer set up. [7.5s]\n",
            "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
            "INFO:sleap.nn.training:Finished creating training datasets. [27.4s]\n",
            "INFO:sleap.nn.training:Starting training loop...\n",
            "Epoch 1/200\n",
            "2024-05-14 11:56:59.363412: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 226492416 exceeds 10% of free system memory.\n",
            "2024-05-14 11:56:59.704111: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 226492416 exceeds 10% of free system memory.\n",
            "2024-05-14 11:57:00.558209: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 113246208 exceeds 10% of free system memory.\n",
            "2024-05-14 11:57:01.626731: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 113246208 exceeds 10% of free system memory.\n",
            "2024-05-14 11:57:04.074380: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 150994944 exceeds 10% of free system memory.\n",
            "200/200 - 1753s - loss: 2.4671e-04 - val_loss: 1.4935e-04 - lr: 1.0000e-04 - 1753s/epoch - 9s/step\n",
            "Epoch 2/200\n",
            "200/200 - 1701s - loss: 1.2217e-04 - val_loss: 1.0344e-04 - lr: 1.0000e-04 - 1701s/epoch - 9s/step\n",
            "Epoch 3/200\n",
            "200/200 - 1732s - loss: 9.4522e-05 - val_loss: 8.9472e-05 - lr: 1.0000e-04 - 1732s/epoch - 9s/step\n",
            "Epoch 4/200\n"
          ]
        }
      ],
      "source": [
        "!sleap-train baseline.centroid.json \"dataset/drosophila-melanogaster-courtship/courtship_labels.slp\" --run_name \"courtship.centroid\" --video-paths \"dataset/drosophila-melanogaster-courtship/20190128_113421.mp4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm3i0ry04IMx"
      },
      "source": [
        "Let's now train a centered-instance model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufbULTDw4Hbh"
      },
      "outputs": [],
      "source": [
        "!sleap-train baseline_medium_rf.topdown.json \"dataset/drosophila-melanogaster-courtship/courtship_labels.slp\" --run_name \"courtship.topdown_confmaps\" --video-paths \"dataset/drosophila-melanogaster-courtship/20190128_113421.mp4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whOf8PaFxYbt"
      },
      "source": [
        "The models (along with the profiles and ground truth data used to train and validate the model) are saved in the `models/` directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBUTQ2Cm44En"
      },
      "outputs": [],
      "source": [
        "!tree models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsKUX661xFK"
      },
      "source": [
        "## Inference\n",
        "Let's run inference with our trained models for centroids and centered instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLtjtq9E1Znr"
      },
      "outputs": [],
      "source": [
        "!sleap-track \"dataset/drosophila-melanogaster-courtship/20190128_113421.mp4\" --frames 0-100 -m \"models/courtship.centroid\" -m \"models/courtship.topdown_confmaps\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzObCUToEqwA"
      },
      "source": [
        "When inference is finished, predictions are saved in a file. Since we didn't specify a path, it will be saved as `<video filename>.predictions.slp` in the same directory as the video:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6KVfWDIDEUe"
      },
      "outputs": [],
      "source": [
        "!tree dataset/drosophila-melanogaster-courtship"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mf3KZQj_GhH"
      },
      "source": [
        "You can inspect your predictions file using `sleap-inspect`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jbVP_s06hMh"
      },
      "outputs": [],
      "source": [
        "!sleap-inspect dataset/drosophila-melanogaster-courtship/20190128_113421.mp4.predictions.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFfHDVy7_iDz"
      },
      "source": [
        "If you're using Chrome you can download your trained models like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej2it8dl_BO_"
      },
      "outputs": [],
      "source": [
        "# Zip up the models directory\n",
        "!zip -r trained_models.zip models/\n",
        "\n",
        "# Download.\n",
        "from google.colab import files\n",
        "files.download(\"/content/trained_models.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iskOQI-r_zNO"
      },
      "source": [
        "And you can likewise download your predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdXCYnRV_omC"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('dataset/drosophila-melanogaster-courtship/20190128_113421.mp4.predictions.slp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fy26NVmCWFw"
      },
      "source": [
        "In some other browsers (Safari) you might get an error and you can instead download using the \"Files\" tab in the side panel (it has a folder icon). Select \"Show table of contents\" in the \"View\" menu if you don't see the side panel."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training and inference on an example dataset",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}